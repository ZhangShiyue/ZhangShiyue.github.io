<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Topic model(LDA)</title>
     <link rel="stylesheet" href="css/templatemo-style.css">
</head>
<body>
<h2 class="tm-text-title">Topic model(LDA)</h2>

<img src="img/lda.png"> <br>
<div class="tm-bg-white-translucent text-xs-left tm-textbox tm-2-col-textbox">
    <p class="tm-text">
        Figure 1 illustrates the basic structure of personalized news recommendation system. It mainly has two layers. One contains
        different kinds of 'recallers' that generate a set of candidates. Each of them is a small recommendation system,
        for example, hotest recaller recommends hot news, similarity recaller recommends news based on Collaborative
        Filtering. The other is a ranking layer that ranks the candidates and return news to users.
    </p>
    <p class="tm-text">
        'LDA recaller' is shown in Figure 2. Recommendation is based on a pretrained LDA model which is trained on all
        news articles, contains 2000 topics and is updated every 6 months. And a 'article content' is represented by its topic vector.
        Similarly, a 'user interest' is represented by the combination of topic vectors of his last-two-week click-through articles.
        Then, input <'user interest', 'article coantent'> into a logistic regression scorer and output the possibility that the
        user will click the article. The 'user interest' and 'logistic regression scorer' should be update every day, since new logs
        come out every day.
    </p>
    <p class="tm-text">
        'LDA recaller' averagely acquired 15% click-through-rate, which means it works quite well. But I should say this a rather
        basic work, because the 'news' we handled were tweets, blogs rather than real-time news, that's why the 'LDA model' doesn't
        have to be updated often. And our data is quite small about 50,000 articles, that's why I only use 2000 topics.
        So, in real-time situation, LDA model should be updated in time, but the slow training process of LDA will be a problem.
        And a huge dataset will make the thing more challenging.There are some works about large and fast LDA, such as
        <a href="http://www.dmtk.io/lightlda.html">LightLDA</a>,
        <a href="https://arxiv.org/pdf/1510.08628.pdf">WarpLDA</a> and <a href="https://arxiv.org/pdf/1405.4402.pdf">Peacock</a>.
    </p>
</div>


</body>
</html>